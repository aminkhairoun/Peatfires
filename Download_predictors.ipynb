{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "685cb198-76fd-4b64-aa7d-b9c6cc9c32ff",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b16c68-92a5-4022-8d50-9ece2f5f25dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T15:28:06.677514Z",
     "start_time": "2024-12-03T15:28:05.489201Z"
    },
    "execution": {
     "iopub.execute_input": "2025-03-05T01:06:44.197876Z",
     "iopub.status.busy": "2025-03-05T01:06:44.193510Z",
     "iopub.status.idle": "2025-03-05T01:06:47.013693Z",
     "shell.execute_reply": "2025-03-05T01:06:47.012907Z",
     "shell.execute_reply.started": "2025-03-05T01:06:44.196905Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, sys, glob, re\n",
    "from osgeo import gdal, osr, ogr\n",
    "from datetime import datetime, timedelta, date, timezone\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "import io\n",
    "import operator\n",
    "import rasterio as rio\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import pyproj\n",
    "import ast\n",
    "from shapely.geometry import Polygon\n",
    "from pyproj import Transformer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e85ed7-16c5-4dad-a86a-728f2a46d21d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T15:28:08.658630Z",
     "start_time": "2024-12-03T15:28:06.702577Z"
    },
    "execution": {
     "iopub.execute_input": "2025-03-05T01:06:51.255801Z",
     "iopub.status.busy": "2025-03-05T01:06:51.255231Z",
     "iopub.status.idle": "2025-03-05T01:06:51.632430Z",
     "shell.execute_reply": "2025-03-05T01:06:51.631736Z",
     "shell.execute_reply.started": "2025-03-05T01:06:51.255758Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import Global_Functions\n",
    "import Gdal_Functions\n",
    "\n",
    "import ee\n",
    "ee.Authenticate(force=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0e324f-2089-40bd-a3a6-8e05e3cc30ce",
   "metadata": {},
   "source": [
    "## 1) NBR, NBR2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e487c9d7-989d-4985-b2eb-375937cedbf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T15:28:22.403332Z",
     "start_time": "2024-12-03T15:28:20.836625Z"
    },
    "execution": {
     "iopub.execute_input": "2024-11-19T16:56:16.804071Z",
     "iopub.status.busy": "2024-11-19T16:56:16.803727Z",
     "iopub.status.idle": "2024-11-19T16:56:17.772144Z",
     "shell.execute_reply": "2024-11-19T16:56:17.771765Z",
     "shell.execute_reply.started": "2024-11-19T16:56:16.804046Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "BA = ee.ImageCollection('projects/ee-fireccihrba/assets/SFD_BA/Siberia/PeatFire/SIN_1km')\n",
    "studyArea = ee.FeatureCollection('users/fireccihrba/BAMT/Regions/Siberia').geometry()\n",
    "grid2d = ee.FeatureCollection(\"users/fireccihrba/BAMT/Regions/Tiles_Siberia_3dLon\")\n",
    "grid4d = ee.FeatureCollection(\"users/fireccihrba/BAMT/Regions/Tiles_Siberia_4dLat\")\n",
    "BA30 = ee.ImageCollection('projects/ee-fireccihrba/assets/SFD_BA/Siberia/PeatFire/JD')\n",
    "print(BA.filter(ee.Filter.eq('system:index', 'BA_Siberia_Lndst_2002_JD_1km')).getInfo())\n",
    "print(f\"\\n\\n{BA30.first().getInfo()}\")\n",
    "print(f\"\\n\\n{grid4d.first().getInfo()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b1c25a-03e5-4d8b-b80e-e21ba80bec65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T12:30:28.181796Z",
     "iopub.status.busy": "2024-11-05T12:30:28.181469Z",
     "iopub.status.idle": "2024-11-05T12:30:28.211312Z",
     "shell.execute_reply": "2024-11-05T12:30:28.210835Z",
     "shell.execute_reply.started": "2024-11-05T12:30:28.181773Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download_image(image, name, export_folder, geo, proj, scale, transform=None, to='Drive',  logfile=False):\n",
    "    if transform:\n",
    "        scale = None\n",
    "    if to == 'Drive':\n",
    "        task = ee.batch.Export.image.toDrive(image=image, \n",
    "                              description=name, \n",
    "                              folder=export_folder, \n",
    "                              crs=proj,  \n",
    "                              scale=scale,\n",
    "                              crsTransform=transform,\n",
    "                              region=geo, \n",
    "                              maxPixels=1e13)  \n",
    "    else:\n",
    "        task = ee.batch.Export.image.toAsset(image=image, \n",
    "                              description=name, \n",
    "                              assetId=f'{export_folder}/{name}', \n",
    "                              crs=proj,  \n",
    "                              scale=scale, \n",
    "                              crsTransform=transform,\n",
    "                              region=geo, \n",
    "                              maxPixels=1e13)              \n",
    "    task.start()\n",
    "    Global_Functions.print_and_log(logfile, f\"\\t\\t +++ Exporting {name} ...\")\n",
    "    \n",
    "def calculate_NBR(year, tile, sensor='Landsat', logfile=False):\n",
    "    if not logfile:\n",
    "        logfile = io.StringIO()\n",
    "    # Global_Functions.print_and_log(logfile, f'\\n\\t\\t{15 * \"-\"} {tile} {15 * \"-\"}')        \n",
    "    studyArea = tile.geometry()\n",
    "    tilename = tile.get('TILE').getInfo()\n",
    "\n",
    "    \"\"\"----- Main functions ------\"\"\"\n",
    "    def get_indices(image):\n",
    "        nbr = image.normalizedDifference(['SWIR2', 'NIR']).multiply(10000).int16()\n",
    "        nbr2 = image.normalizedDifference(['SWIR2', 'SWIR1']).multiply(10000).int16()\n",
    "        return image.int16().addBands([nbr.rename(['NBR']), nbr2.rename(['NBR2'])])\n",
    "\n",
    "    def mask_landsat(image):\n",
    "        date = ee.Number.parse(ee.Date(image.get('system:time_start')).format('yyyyDDD'))\n",
    "        mask = image.select('QA_PIXEL').bitwiseAnd(ee.Number(2).pow(3).int()).eq(0) \\\n",
    "            .And(image.select('QA_PIXEL').bitwiseAnd(ee.Number(2).pow(4).int()).eq(0)) \\\n",
    "            .And(image.select('QA_PIXEL').bitwiseAnd(ee.Number(2).pow(2).int()).eq(0)) \\\n",
    "            .And(image.select('QA_PIXEL').bitwiseAnd(ee.Number(2).pow(5).int()).eq(0))\n",
    "        satellite = ee.String(image.get('SPACECRAFT_ID'))\n",
    "        image = ee.Image(ee.Algorithms.If(\n",
    "        satellite.compareTo('LANDSAT_4').eq(0) \\\n",
    "          .Or(satellite.compareTo('LANDSAT_5').eq(0)) \\\n",
    "          .Or(satellite.compareTo('LANDSAT_7').eq(0)),\n",
    "        image.select(['SR_B3', 'SR_B4', 'SR_B5', 'SR_B7']) \\\n",
    "          .multiply(0.0000275).add(-0.2).multiply(10000) \\\n",
    "          .rename(['Red', 'NIR', 'SWIR1', 'SWIR2']),\n",
    "        image.select(['SR_B4', 'SR_B5', 'SR_B6', 'SR_B7']) \\\n",
    "          .multiply(0.0000275).add(-0.2).multiply(10000) \\\n",
    "          .rename(['Red', 'NIR', 'SWIR1', 'SWIR2'])\n",
    "        ))\n",
    "        image = image.updateMask(mask.eq(1))\n",
    "        image = image.updateMask(image.select('NIR').gt(50).And(image.select('Red').gt(50)))\n",
    "            ## additional mask for clouds missed by CFMask, here NIR is more restrictive\n",
    "        image = image.updateMask(image.select('SWIR2').lt(3000).And(image.select('NIR').lt(2600)))             \n",
    "        return image.clip(studyArea)\n",
    "    \n",
    "    def mask_MOD09(image):\n",
    "        mask = image.select('state_1km').bitwiseAnd(ee.Number(2).pow(10).int()).eq(0)  \\\n",
    "              .And(image.select('state_1km').bitwiseAnd(ee.Number(2).pow(15).int()).eq(0)) ## Snow   \n",
    "        image = image.select(['sur_refl_b02', 'sur_refl_b06', 'sur_refl_b07']) \\\n",
    "                    .rename(['NIR', 'SWIR1', 'SWIR2'])        \n",
    "        return image.updateMask(mask)\n",
    "        \n",
    "    \"\"\"----- Processing ------\"\"\"\n",
    "\n",
    "    if sensor == 'Landsat':\n",
    "        date_1 = f'{int(year)-2}-03-01'\n",
    "        date_2 = f'{int(year)-1}-12-01'\n",
    "        date_2_2 = f'{int(year)}-03-01'\n",
    "        date_3 = f'{int(year)+1}-12-01'\n",
    "        pre_image = ee.ImageCollection('LANDSAT/LT04/C02/T1_L2').filterBounds(studyArea).filterDate(date_1, date_2) \\\n",
    "            .merge(ee.ImageCollection('LANDSAT/LT05/C02/T1_L2').filterBounds(studyArea).filterDate(date_1, date_2)) \\\n",
    "            .merge(ee.ImageCollection('LANDSAT/LE07/C02/T1_L2').filterBounds(studyArea).filterDate(date_1, date_2)) \\\n",
    "            .merge(ee.ImageCollection('LANDSAT/LC08/C02/T1_L2').filterBounds(studyArea).filterDate(date_1, date_2)) \\\n",
    "            .map(mask_landsat).map(get_indices).select(['NBR', 'NBR2'])\n",
    "\n",
    "        post_image = ee.ImageCollection('LANDSAT/LT04/C02/T1_L2').filterBounds(studyArea).filterDate(date_2_2, date_3) \\\n",
    "            .merge(ee.ImageCollection('LANDSAT/LT05/C02/T1_L2').filterBounds(studyArea).filterDate(date_2_2, date_3)) \\\n",
    "            .merge(ee.ImageCollection('LANDSAT/LE07/C02/T1_L2').filterBounds(studyArea).filterDate(date_2_2, date_3)) \\\n",
    "            .merge(ee.ImageCollection('LANDSAT/LC08/C02/T1_L2').filterBounds(studyArea).filterDate(date_2_2, date_3)) \\\n",
    "            .map(mask_landsat).map(get_indices).select(['NBR', 'NBR2'])\n",
    "    else:\n",
    "        date_1 = f'{int(year)-1}-03-01'\n",
    "        date_2 = f'{int(year)-1}-12-01'\n",
    "        date_2_2 = f'{int(year)}-03-01'\n",
    "        date_3 = f'{int(year)}-12-01'\n",
    "        pre_image = ee.ImageCollection(\"MODIS/061/MOD09GA\").filterDate(date_1, date_2).map(\n",
    "            mask_MOD09).map(get_indices).select(['NBR', 'NBR2'])\n",
    "        post_image = ee.ImageCollection(\"MODIS/061/MOD09GA\").filterDate(date_2_2, date_3).map(\n",
    "            mask_MOD09).map(get_indices).select(['NBR', 'NBR2'])\n",
    "    \n",
    "    proj = 'EPSG:4326'\n",
    "    pre_image = pre_image.median().rename(['NBR', 'NBR2'])\n",
    "    post_image = post_image.qualityMosaic('NBR')\n",
    "    bandtype = post_image.bandTypes().get('NBR')\n",
    "    diff_image = post_image.rename(['post_NBR', 'post_NBR2']).addBands(\n",
    "                   post_image.subtract(pre_image).rename(['diff_NBR', 'diff_NBR2'])) \\\n",
    "                   .cast({'diff_NBR': bandtype, 'diff_NBR2': bandtype})\n",
    "\n",
    "    # BA_image = BA.filter(ee.Filter.eq('system:index', f'BA_Siberia_Lndst_{year}_JD_1km')).first()\n",
    "    BA_image = BA30.filter(ee.Filter.eq('system:index', \n",
    "                f'BAMT_BA_Siberia_Lndst_{year}_TILE-{tilename}_JD_Correct_Patches')).first()\n",
    "    BA_image = BA30.filter(ee.Filter.stringContains('system:index', \n",
    "                f'{year}')).mosaic()\n",
    "    # print(BA_image.getInfo())\n",
    "    diff_image = diff_image.updateMask(BA_image.gt(0))\n",
    "    # print(diff_image.getInfo())\n",
    "    gt = ee.String(tile.get('transform'))\n",
    "    gt = gt.slice(1, -1).split(',').map(lambda x: ee.Number.parse(x))\n",
    "    # print(gt.getInfo())\n",
    "    download_image(diff_image, f'NBR_{year}_{tilename}', 'PeatFire', studyArea, proj, scale=None, \n",
    "                   transform=gt, logfile=logfile)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb99fa18-55b2-4a73-9eb0-041aa210cbd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "calculate_NBR(2023, studyArea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3d9f26-444f-46a3-be6c-4e912d6c5d03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T12:34:42.771033Z",
     "iopub.status.busy": "2024-11-05T12:34:42.770853Z",
     "iopub.status.idle": "2024-11-05T12:34:49.277390Z",
     "shell.execute_reply": "2024-11-05T12:34:49.276873Z",
     "shell.execute_reply.started": "2024-11-05T12:34:42.771019Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "Tiles = grid4d.aggregate_array('TILE').getInfo()\n",
    "for year in list(range(2023, 2000, -1))[:]:\n",
    "    print(year)\n",
    "    for tile in Tiles[:]:\n",
    "            tile = grid4d.filter(ee.Filter.eq('TILE', tile)).first()\n",
    "            # print(tile.getInfo())\n",
    "            calculate_NBR(year, tile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e00b0e-acb3-43a9-850c-2f22be350603",
   "metadata": {},
   "source": [
    "## 2) SoilGrids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a99da5-d83f-47f7-b93b-b4ec5c91963b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T09:56:31.628945Z",
     "iopub.status.busy": "2024-11-11T09:56:31.628758Z",
     "iopub.status.idle": "2024-11-11T09:56:40.491003Z",
     "shell.execute_reply": "2024-11-11T09:56:40.490446Z",
     "shell.execute_reply.started": "2024-11-11T09:56:31.628929Z"
    }
   },
   "outputs": [],
   "source": [
    "local_path = '/media/amin/STORAGE/STORAGE/OneDrive/PhD/Landsat_BA'\n",
    "sib3d = gpd.read_file(f'{local_path}/Regions/Tiles_Siberia_3dLon.shp')\n",
    "layers = ['sand', 'silt', 'clay']\n",
    "\"\"\" The coefficients should ideally be [0-5]: 1/6, [5-15]: 1/3, [15-30]: 1/2 \n",
    "    However, since the fire attacks the top layers first we use 1/3 for all\"\"\"\n",
    "res = 250\n",
    "igh = \"+proj=igh +lat_0=0 +lon_0=0 +datum=WGS84 +units=m +no_defs\" # proj string for Homolosine projection\n",
    "transformer = Transformer.from_crs(\"epsg:4326\", pyproj.CRS.from_proj4(igh), always_xy=True)\n",
    "\n",
    "\n",
    "for i, row in enumerate(list(sib3d.iterrows())[:]):\n",
    "    tile = 'TILE-' + row[1]['TILE']\n",
    "    poly = row[1]['geometry']\n",
    "    poly_igh = Polygon([transformer.transform(x, y) for x, y in poly.exterior.coords]) \n",
    "    gt = ast.literal_eval(row[1]['transform'])\n",
    "    ## xmin, ymax, xmax, ymin\n",
    "    bb = poly_igh.bounds\n",
    "    bb = bb[0], bb[3], bb[2], bb[1]\n",
    "    print(i+1, tile, bb)\n",
    "    # bb = (-337500.000,1242500.000,152500.000,527500.000)\n",
    "    location = \"https://files.isric.org/soilgrids/latest/data/\"\n",
    "    sg_url = f\"/vsicurl?max_retry=3&retry_delay=1&list_dir=no&url={location}\"\n",
    "    \n",
    "    kwargs = {'format': 'GTiff', 'projWin': bb, 'projWinSRS': igh, 'xRes': res, 'yRes': res, \n",
    "              'creationOptions': [\"TILED=YES\", \"COMPRESS=LZW\", \"PREDICTOR=2\", \"BIGTIFF=YES\"]}\n",
    "    for l in layers[:]:\n",
    "        print(l)\n",
    "        ds0_5 = gdal.Translate(f'/vsimem/{l}_0-5cm_igh.tif', \n",
    "                        sg_url + f'{l}/{l}_0-5cm_mean.vrt', \n",
    "                        **kwargs).ReadAsArray()\n",
    "        ds5_15 = gdal.Translate(f'/vsimem/{l}_5-15cm_igh.tif', \n",
    "                        sg_url + f'{l}/{l}_5-15cm_mean.vrt', \n",
    "                        **kwargs).ReadAsArray()\n",
    "        ds15_30 = gdal.Translate(f'/vsimem/{l}_15-30cm_igh.tif', \n",
    "                        sg_url + f'{l}/{l}_15-30cm_mean.vrt', \n",
    "                        **kwargs).ReadAsArray()\n",
    "        with rio.open(f'/vsimem/{l}_0-5cm_igh.tif') as src:\n",
    "            profile = src.profile\n",
    "        [gdal.Unlink(f'/vsimem/{l}_{i}-{j}cm_igh.tif') for (i, j) in zip([0, 5, 15], [5, 15, 30])]\n",
    "        arr = np.nanmean(np.stack([ds0_5, ds5_15, ds15_30], axis=2), axis=2)\n",
    "        del ds15_30, ds5_15, ds0_5\n",
    "        # Global_Functions.write_rasterio(arr, f'{local_path}/Siberia/PeatFire/BG_CC/data/SoilGrids/SoilGrids_{l}_v2.0.tif',\n",
    "        #                                profile=profile)\n",
    "        Global_Functions.write_rasterio(arr, f'/vsimem/{l}_{tile}_igh.tif',\n",
    "                                       profile=profile)\n",
    "        profile['transform'] = gt\n",
    "        profile['height'] = 8000\n",
    "        profile['width'] = 12000\n",
    "        profile['crs'] = pyproj.CRS.from_epsg(4326)\n",
    "        # print(profile)\n",
    "        os.makedirs(f'{local_path}/Siberia/PeatFire/ByTile/{tile}/Predictors', exist_ok=True)\n",
    "        Global_Functions.resample_by_ref(f'/vsimem/{l}_{tile}_igh.tif', \n",
    "                f'{local_path}/Siberia/PeatFire/ByTile/{tile}/Predictors/SoilGrids_{l}_{tile}_v2.0.tif',\n",
    "                                profile=profile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256e6de8-bd30-4eda-8a61-49ec210e8da0",
   "metadata": {},
   "source": [
    "## 3) TerraClimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20873c0c-cf61-4e4a-a1f1-74f7c1c7fe2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T15:28:36.069638Z",
     "start_time": "2024-12-03T15:28:35.788415Z"
    },
    "execution": {
     "iopub.execute_input": "2024-11-19T17:11:56.967063Z",
     "iopub.status.busy": "2024-11-19T17:11:56.966765Z",
     "iopub.status.idle": "2024-11-19T17:11:57.302609Z",
     "shell.execute_reply": "2024-11-19T17:11:57.302148Z",
     "shell.execute_reply.started": "2024-11-19T17:11:56.967036Z"
    }
   },
   "outputs": [],
   "source": [
    "terraClimate = ee.ImageCollection(\"IDAHO_EPSCOR/TERRACLIMATE\")\n",
    "cems_ic = ee.ImageCollection('projects/climate-engine-pro/assets/ce-cems-fire-daily-4-1')\n",
    "cems_avg_list = ee.data.listAssets('projects/ee-fireccihrba/assets/SFD_BA/Siberia/PeatFire/CEMS_ECMWF')['assets']\n",
    "cems_avg = ee.ImageCollection(list(map(lambda x: ee.Image(x['id']), cems_avg_list)))\n",
    "# cems_avg = ee.ImageCollection([ee.Image(x['id']) for x in cems_avg_list if 'DC' in x['id']])\n",
    "\n",
    "def download_image(image, name, export_folder, geo, proj, scale, transform=None, to='Drive', logfile=False):\n",
    "    if not logfile:\n",
    "        logfile = io.StringIO()\n",
    "    if transform:\n",
    "        scale = None\n",
    "    if to == 'Drive':\n",
    "        task = ee.batch.Export.image.toDrive(image=image, \n",
    "                              description=name, \n",
    "                              folder=export_folder, \n",
    "                              crs=proj,  \n",
    "                              scale=scale,\n",
    "                              crsTransform=transform,\n",
    "                              region=geo, \n",
    "                              maxPixels=1e13)  \n",
    "    else:\n",
    "        task = ee.batch.Export.image.toAsset(image=image, \n",
    "                              description=name, \n",
    "                              assetId=f'{export_folder}/{name}', \n",
    "                              crs=proj,  \n",
    "                              scale=scale, \n",
    "                              crsTransform=transform,\n",
    "                              region=geo, \n",
    "                              maxPixels=1e13)              \n",
    "    task.start()\n",
    "    Global_Functions.print_and_log(logfile, f\"\\t\\t +++ Exporting {name} ...\")\n",
    "\n",
    "\n",
    "def get_lngTerm_stat(col, stat, months=[6, 9]):\n",
    "    ## If you filter the year ypu will have a changing stats, not a worthed heavy processing\n",
    "     # .filter(ee.Filter.calendarRange(int(year), int(year), 'year').Not()) \n",
    "    lngTerm = col.filter(ee.Filter.calendarRange(months[0], months[1], 'month')) \\\n",
    "        .map(lambda img: img.set('year', ee.Date(img.get('system:time_start')).get('year')))\n",
    "    distYear = lngTerm.distinct('year')\n",
    "    joinedCol = ee.Join.saveAll('sameYear').apply(distYear, lngTerm, \n",
    "                     ee.Filter.equals(**{'leftField': 'year', 'rightField': 'year'}))\n",
    "    lngTerm_stat = ee.ImageCollection(joinedCol.map(lambda img: ee.ImageCollection.fromImages(img.get('sameYear')) \\\n",
    "                                .reduce(stat).set('year', img.get('year'))))\n",
    "    return lngTerm_stat\n",
    "\n",
    "def get_summer_stats(col, band, stat, date_start, date_end, lngTerm_stat=None):\n",
    "    subset = col.select(band).filterDate(date_start, date_end)\n",
    "    result = subset.reduce(stat)\n",
    "    if not lngTerm_stat:\n",
    "        lngTerm_stat = get_lngTerm_stat(col.select(band), stat, months=[6, 9])\n",
    "    anomaly = result.subtract(lngTerm_stat.reduce(ee.Reducer.mean())).divide(lngTerm_stat.reduce(ee.Reducer.stdDev()))\n",
    "    return result, anomaly\n",
    "\n",
    "def get_cumulative_stats(col, band, stat, date_start, date_end):\n",
    "    col = col.select(band)\n",
    "    days_list = col.aggregate_array('system:index').getInfo()\n",
    "    years_list = np.unique([i[:4] for i in days_list])\n",
    "    years_list = ee.List(years_list.tolist())\n",
    "    init_col = ee.ImageCollection([])\n",
    "    def cumulative_stat(y, cum_col):\n",
    "        # start = ee.Date(ee.Number.parse(y).format('%d-06-01'))\n",
    "        # end = ee.Date(ee.Number.parse(y).format('%d-10-01'))\n",
    "        start = ee.Date(date_start).update(year=ee.Number.parse(y))\n",
    "        end = ee.Date(date_end).update(year=ee.Number.parse(y))\n",
    "        image_stat = ee.ImageCollection(col).filterDate(start, end).reduce(stat).set('year', y)\n",
    "        return ee.ImageCollection(cum_col).merge(image_stat)\n",
    "    \n",
    "    cumul_stat = ee.ImageCollection(years_list.iterate(cumulative_stat, init_col))\n",
    "    result = cumul_stat.filter(ee.Filter.eq('year', date_start[:4])).first()\n",
    "    anomaly = result.subtract(cumul_stat.reduce(ee.Reducer.mean())).divide(cumul_stat.reduce(ee.Reducer.stdDev()))   \n",
    "    return result, anomaly\n",
    "\n",
    "def get_annual(col, band, stat, date_start, date_end):\n",
    "    lngTerm = col.filterDate(date_start, date_end).select(band)\n",
    "    lngTermStat = lngTerm.reduce(stat).set('year', date_start[:4])\n",
    "    return lngTermStat\n",
    "    \n",
    "    \n",
    "def get_terraclimate(year, studyArea, tile=None, logfile=False):\n",
    "    if not logfile:\n",
    "        logfile = io.StringIO()\n",
    "\n",
    "    if tile:    \n",
    "        studyArea = tile.geometry()\n",
    "        tilename = tile.get('TILE').getInfo()    \n",
    "    date_start = f'{year}-06-01'\n",
    "    date_end = f'{year}-10-01'\n",
    "    \n",
    "    \"\"\"----- Main functions ------\"\"\"\n",
    "\n",
    "    def get_yearly_mcwd(y, mcwd_lngterm):\n",
    "        start = ee.Date(ee.Number(y).format('%d-01-01'))\n",
    "        end = ee.Date(ee.Number(y).format('%d-10-01'))\n",
    "        rain = terraClimate.select('pr').filterDate(start, end)\n",
    "        evap = terraClimate.select('aet').filterDate(start, end).map(lambda image: image.multiply(0.1))\n",
    "        acc_wd_rec = ee.ImageCollection([])\n",
    "        \n",
    "        def get_mcwd(aet, acc_wd):\n",
    "            ide = aet.get('system:index')\n",
    "            p = rain.filter(ee.Filter.eq('system:index', ide)).first()\n",
    "            aet = evap.filter(ee.Filter.eq('system:index', ide)).first()\n",
    "            water_deficit = aet.subtract(p).multiply(aet.gte(p))\n",
    "            ## the same result as the following\n",
    "            # water_deficit = aet.subtract(p).updateMask(aet.gte(p)).unmask(0)\n",
    "            return ee.ImageCollection(acc_wd).merge(water_deficit)\n",
    "        \n",
    "        mcwd_rec = ee.ImageCollection(evap.iterate(get_mcwd, acc_wd_rec)).sum().rename('mcdw')\n",
    "        mcwd_rec = mcwd_rec.set('system:time_start', start).set('system:time_end', end)\n",
    "        return ee.ImageCollection(mcwd_lngterm).merge(mcwd_rec)\n",
    "        \n",
    "\n",
    "    \"\"\"----- Processing ------\"\"\"\n",
    "\n",
    "    bands = ['tmmx', 'tmmn', 'vpd', 'srad', 'pdsi', 'def', 'soil']\n",
    "    layers = ['Tmax', 'Tmin', 'vpd', 'solar_down', 'pdsi', 'cwd', 'moisture']\n",
    "    terra_stats = get_cumulative_stats(terraClimate, bands,\n",
    "            ee.Reducer.mean(), date_start, date_end)\n",
    "    \n",
    "    \n",
    "    # print(terra_stats[0].bandNames().getInfo())\n",
    "    anomaly_layers = [f'{l}_anomaly' for l in layers]\n",
    "    monthly_means = terra_stats[0].rename(layers)\n",
    "    monthly_anomalies = terra_stats[1].rename(anomaly_layers)\n",
    "\n",
    "    ## Drought Code\n",
    "    bands_cems = ['duff_moisture_code', 'fine_fuel_moisture_code', 'fire_weather_index', 'drought_code']\n",
    "    layers_cems = ['duff_moisture', 'finefuel_moisture', 'FWI', 'DC']\n",
    "    cems_mean, cems_mean_anomaly = get_summer_stats(cems_ic, \n",
    "            bands_cems,  ee.Reducer.mean(), \n",
    "            date_start, date_end, lngTerm_stat=cems_avg)\n",
    "    anomaly_layers_cems = [f'{l}_anomaly' for l in layers_cems]\n",
    "    monthly_cems_means = cems_mean.rename(layers_cems)\n",
    "    monthly_cems_anomalies = cems_mean_anomaly.rename(anomaly_layers_cems)    \n",
    "\n",
    "    layers = {\n",
    "              'TerraClimate_Means': monthly_means, \n",
    "              'TerraClimate_Anomalies': monthly_anomalies,\n",
    "              'ECMWF_CEMS_Means': monthly_cems_means,\n",
    "              'ECMWF_CEMS_Anomalies': monthly_cems_anomalies\n",
    "             }\n",
    "    for i in layers.items():\n",
    "        if 'Terra' in i[0]:\n",
    "            proj = terraClimate.first().projection().getInfo()\n",
    "        else:\n",
    "            proj = cems_ic.first().projection().getInfo()\n",
    "\n",
    "        # print(proj)\n",
    "        crs = 'EPSG:4326'\n",
    "        gt = proj['transform']\n",
    "        naming = f'{i[0]}_Siberia_{year}'\n",
    "        if tile:\n",
    "            naming = f'{i[0]}_Siberia_{year}_{tilename}'\n",
    "        download_image(i[1], naming, 'PeatFire', studyArea, crs, scale=None, \n",
    "                   transform=gt, logfile=logfile)\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543395f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T01:36:52.902219Z",
     "start_time": "2024-11-27T01:36:51.181383Z"
    }
   },
   "outputs": [],
   "source": [
    "bands = ['tmmx', 'tmmn', 'vpd', 'srad', 'pdsi', 'def', 'soil']\n",
    "layers = ['Tmax', 'Tmin', 'vpd', 'solar_down', 'pdsi', 'cwd', 'moisture']\n",
    "Lngterm = get_lngTerm_stat(terraClimate.select(bands), ee.Reducer.mean(), months=[6, 9])\n",
    "stats = {\n",
    "        'LongTermMean': ee.Reducer.mean(),\n",
    "        'LongTermSTD': ee.Reducer.stdDev()}\n",
    "for l, s in stats.items(): \n",
    "    image = Lngterm.reduce(s).rename(layers)\n",
    "    proj = terraClimate.first().projection().getInfo()\n",
    "    crs = 'EPSG:4326'\n",
    "    gt = proj['transform']\n",
    "    naming = f'TerraClimate_{l}_Siberia'\n",
    "    download_image(image, naming, 'PeatFire', studyArea, crs, scale=None, \n",
    "                   transform=gt, logfile=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bf2f77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T14:58:54.234554Z",
     "start_time": "2024-11-27T14:58:54.070088Z"
    }
   },
   "outputs": [],
   "source": [
    "bands = ['duff_moisture_code', 'fine_fuel_moisture_code', 'fire_weather_index', 'drought_code']\n",
    "layers = ['DMC', 'FFMC', 'FWI', 'DC']\n",
    "Lngterm = cems_avg\n",
    "stats = {\n",
    "        'LongTermMean': ee.Reducer.mean(),\n",
    "        'LongTermSTD': ee.Reducer.stdDev()}\n",
    "for l, s in stats.items(): \n",
    "    image = Lngterm.reduce(s).rename(layers).select(['DMC', 'FFMC', 'DC'])\n",
    "    proj = cems_ic.first().projection().getInfo()\n",
    "    crs = 'EPSG:4326'\n",
    "    gt = proj['transform']\n",
    "    naming = f'ECMWF_CEMS_{l}_Siberia'\n",
    "    download_image(image, naming, 'PeatFire', studyArea, crs, scale=None, \n",
    "                   transform=gt, logfile=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eeacc40-71c1-4460-badd-fd0ce6479552",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T11:23:57.372033Z",
     "start_time": "2024-11-27T11:22:21.751346Z"
    },
    "execution": {
     "iopub.execute_input": "2024-11-19T17:12:07.879666Z",
     "iopub.status.busy": "2024-11-19T17:12:07.879386Z",
     "iopub.status.idle": "2024-11-19T17:13:03.355497Z",
     "shell.execute_reply": "2024-11-19T17:13:03.355042Z",
     "shell.execute_reply.started": "2024-11-19T17:12:07.879647Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Extent = ee.Geometry.BBox(63, 58, 180, 74)\n",
    "Tiles = grid4d.aggregate_array('TILE').getInfo()\n",
    "for year in list(range(2023, 1939, -1))[:]:\n",
    "    print(year)\n",
    "    get_terraclimate(year, Extent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50c3582-04b3-48c3-a59e-38946b94e3c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T19:40:02.437200Z",
     "iopub.status.busy": "2024-10-31T19:40:02.436649Z",
     "iopub.status.idle": "2024-10-31T19:40:03.292976Z",
     "shell.execute_reply": "2024-10-31T19:40:03.292235Z",
     "shell.execute_reply.started": "2024-10-31T19:40:02.437155Z"
    }
   },
   "source": [
    "## 4) LST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce3cc23-cc4a-4a78-8054-7f85888cc3d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T02:43:32.224866Z",
     "start_time": "2024-11-23T02:43:32.193816Z"
    }
   },
   "outputs": [],
   "source": [
    "Tiles_MODIS_gee = ee.FeatureCollection(\"users/fireccihrba/BAMT/Regions/MODIS_GRID_WGS84\")\n",
    "\n",
    "def get_summer_stats(col, band, stat, date_start, date_end):\n",
    "    subset = col.select(band).filterDate(date_start, date_end)\n",
    "    result = subset.reduce(stat)\n",
    "    lngTerm_stat = get_lngTerm_stat(col.select(band), stat, months=[7, 8])\n",
    "    anomaly = result.subtract(lngTerm_stat.reduce(ee.Reducer.mean())).divide(lngTerm_stat.reduce(ee.Reducer.stdDev()))\n",
    "    return result, anomaly\n",
    "\n",
    "def get_cumulative_stats(col, band, stat, date_start, date_end):\n",
    "    col = col.select(band)\n",
    "    days_list = col.aggregate_array('system:index')#.getInfo()\n",
    "    # years_list = np.unique([i[:4] for i in days_list])\n",
    "    # years_list = ee.List(years_list.tolist())\n",
    "    years_list = ee.List(days_list).map(lambda x: ee.String(x).slice(0, 4)).distinct()\n",
    "    init_col = ee.ImageCollection([])\n",
    "    def cumulative_stat(y, cum_col):\n",
    "        start = ee.Date(ee.Number.parse(y).format('%d-07-01'))\n",
    "        end = ee.Date(ee.Number.parse(y).format('%d-09-01'))\n",
    "        single_year = ee.ImageCollection(col).filterDate(start, end).set('year', y).rename()\n",
    "        stat_image = single_year.reduce(stat).rename('stat_image')#.set('system:index','2000_01_01') ## make fixed distinct date easy to pick\n",
    "        single_year = single_year.merge(stat_image).toBands()\n",
    "        return ee.ImageCollection(cum_col).merge(single_year)\n",
    "    \n",
    "    cumul_stat = ee.ImageCollection(years_list.iterate(cumulative_stat, init_col))\n",
    "    overall_stat = cumul_stat.select('.*stat_image')\n",
    "    LST_mean = overall_stat.filter(ee.Filter.eq('year', ee.String(date_start).slice(0, 4)))\n",
    "    anomaly = LST_mean.subtract(overall_stat.reduce(ee.Reducer.mean())).divide(overall_stat.reduce(ee.Reducer.stdDev())) \n",
    "    print(LST_mean.getInfo())\n",
    "    return LST_mean, anomaly\n",
    "\n",
    "def download_image(image, name, export_folder, geo, proj, scale, transform=None, to='Drive', logfile=False):\n",
    "    if transform:\n",
    "        scale = None\n",
    "    if to == 'Drive':\n",
    "        task = ee.batch.Export.image.toDrive(image=image, \n",
    "                              description=name, \n",
    "                              folder=export_folder, \n",
    "                              crs=proj,  \n",
    "                              scale=scale,\n",
    "                              crsTransform=transform,\n",
    "                              region=geo, \n",
    "                              maxPixels=1e13)  \n",
    "    else:\n",
    "        task = ee.batch.Export.image.toAsset(image=image, \n",
    "                              description=name, \n",
    "                              assetId=f'{export_folder}/{name}', \n",
    "                              crs=proj,  \n",
    "                              scale=scale, \n",
    "                              crsTransform=transform,\n",
    "                              region=geo, \n",
    "                              maxPixels=1e13)              \n",
    "    task.start()\n",
    "    Global_Functions.print_and_log(logfile, f\"\\t\\t +++ Exporting {name} ...\")\n",
    "    \n",
    "def LST_anomaly(year, studyArea, tile=None, satellite='Terra', logfile=False):\n",
    "    if not logfile:\n",
    "        logfile = io.StringIO()\n",
    "\n",
    "    if tile:    \n",
    "        studyArea = tile.geometry()\n",
    "        tilename = tile.get('TILE').getInfo()    \n",
    "    date_start = f'{year}-07-01'\n",
    "    date_end = f'{year}-09-01'  \n",
    "    stat = ee.Reducer.mean()\n",
    "    \"\"\"----- Main functions ------\"\"\"    \n",
    "    def preprocess_LST(image):\n",
    "        rescaled = image.multiply(0.02)\n",
    "        rescaled = rescaled.set('system:time_start', image.get('system:time_start')) \n",
    "        rescaled = rescaled.set('system:time_end', image.get('system:time_end'))\n",
    "        return rescaled\n",
    "\n",
    "    def filter_doy(d, deltamin, deltamax, y):\n",
    "        doymax = int((datetime.strptime(f'{y+1}0101', '%Y%m%d') - timedelta(days=1)).strftime('%j'))\n",
    "        doymax0 = int((datetime.strptime(f'{y}0101', '%Y%m%d') - timedelta(days=1)).strftime('%j'))\n",
    "        if (d + deltamax) > doymax:\n",
    "            filter1max = ee.Filter.dayOfYear(int(d - deltamin), doymax)\n",
    "            filter2max = ee.Filter.dayOfYear(1, int(d + deltamax - doymax))\n",
    "            result_filter = ee.Filter.Or(filter1max, filter2max)\n",
    "        elif (d - deltamin) < 1:\n",
    "            filter1min = ee.Filter.dayOfYear(int(d - deltamin + doymax0), doymax0)\n",
    "            filter2min = ee.Filter.dayOfYear(1, int(d + deltamax))\n",
    "            result_filter = ee.Filter.Or(filter1min, filter2min)\n",
    "        else:\n",
    "            result_filter = ee.Filter.dayOfYear(int(d - deltamin), int(d + deltamax))\n",
    "        return result_filter\n",
    "                                           \n",
    "    \"\"\"----- Processing ------\"\"\"\n",
    "    \n",
    "    if satellite == 'Aqua':\n",
    "        ## \n",
    "        modis_11 = ee.ImageCollection(\"MODIS/061/MYD11A2\")\n",
    "    elif satellite == 'Terra':\n",
    "        ## pass time 10:30 pm, most \n",
    "        modis_11 = ee.ImageCollection(\"MODIS/061/MOD11A2\")\n",
    "        \n",
    "    modis_11 = modis_11.select('LST_Night_1km')\n",
    "    days_list = modis_11.aggregate_array('system:index')\n",
    "    ini = ee.List([])\n",
    "    years_list = ee.List(days_list).map(lambda x: ee.String(x).slice(0, 4)).distinct()\n",
    "    init_col = ee.ImageCollection([])\n",
    "    def cumulative_stat(y, cum_col):\n",
    "        start = ee.Date(ee.Number.parse(y).format('%d-06-01'))\n",
    "        end = ee.Date(ee.Number.parse(y).format('%d-10-01'))\n",
    "        single_year = ee.ImageCollection(modis_11).filterDate(start, end).toBands()\n",
    "        doys = single_year.bandNames().map(lambda x: \n",
    "                   ee.Number.parse(ee.Date.parse('yyyy_MM_dd', ee.String(x).slice(0, 10)).format('D')))\n",
    "        periods = doys.map(lambda x: ee.Number(x).divide(8).int())\n",
    "        ini = ee.List([])\n",
    "        names = periods.iterate(lambda x, ini: \n",
    "                   ee.List(ini).add(ee.String('image_').cat(ee.Number(x).format('%d'))), ini)\n",
    "        \n",
    "        single_year = single_year.rename(names)\n",
    "        bandtype = single_year.select('image_19').bandTypes().get('image_19')\n",
    "        single_year = ee.Image(ee.Algorithms.If(ee.String(y).compareTo('2001').eq(0), \n",
    "                  single_year.addBands(single_year.select(['image_20', 'image_22']).reduce('mean').rename('image_21').cast({'image_21': bandtype})), \n",
    "                                                single_year))\n",
    "        stat_image = single_year.reduce(stat).rename('stat_image')\n",
    "        single_year = single_year.addBands(stat_image).set('year', y)\n",
    "        return ee.ImageCollection(cum_col).merge(single_year)\n",
    "    \n",
    "    cumul_stat = ee.ImageCollection(years_list.iterate(cumulative_stat, init_col))\n",
    "    overall_stat = cumul_stat.select('.*stat_image')\n",
    "    LST_mean = overall_stat.filter(ee.Filter.eq('year', ee.String(date_start).slice(0, 4))).first()\n",
    "    anomaly = LST_mean.subtract(overall_stat.reduce(ee.Reducer.mean())).divide(overall_stat.reduce(ee.Reducer.stdDev())) \n",
    "    year_image = cumul_stat.filter(ee.Filter.eq('year', ee.String(date_start).slice(0, 4))).first()\n",
    "    periods = year_image.select('[^.*stat].*').bandNames()\n",
    "    init_col = ee.ImageCollection([])\n",
    "    def get_period_anomaly(p, col):\n",
    "        p = ee.String(p)\n",
    "        subset = cumul_stat.select(p)\n",
    "        subset_year = year_image.select(p)\n",
    "        result = subset_year.subtract(subset.reduce(ee.Reducer.mean())).divide(subset.reduce(ee.Reducer.stdDev())) \n",
    "        result = result.where(result.gte(0.5), 1)\n",
    "        result = result.where(result.lt(0.5), 0).rename('anomaly')\n",
    "        return ee.ImageCollection(col).merge(result)\n",
    "    \n",
    "    period_anomaly = ee.ImageCollection(periods.iterate(get_period_anomaly, init_col)) \n",
    "    prop = period_anomaly.reduce(ee.Reducer.sum()).divide(period_anomaly.reduce(ee.Reducer.count()))\n",
    "    \n",
    "    ## Use the proper scale otherwise you might end up having slight misgeolocation\n",
    "    LST_stat = LST_mean.rename('mean_LST')#.updateMask(BA_image.gt(0))\n",
    "    LST_anomaly = anomaly.rename('LST_std_anomaly')#.updateMask(BA_image.gt(0))\n",
    "    LST_persistence = prop.rename('LST_persistence')#.updateMask(BA_image.gt(0))\n",
    "    layers = {\n",
    "              'LST_Mean_JA': LST_stat, \n",
    "              'LST_std_anomaly_JA': LST_anomaly,\n",
    "              'LST_persistence_JA': LST_persistence,\n",
    "             }\n",
    "    for i in layers.items():\n",
    "        proj = modis_11.first().projection().getInfo()\n",
    "        crs = proj['crs']\n",
    "        crs = 'EPSG:4326'\n",
    "        gt = proj['transform']\n",
    "        scale = gt[0]\n",
    "        print(crs, gt)\n",
    "        naming = f'{i[0]}_Siberia_{year}'\n",
    "        if tile:\n",
    "            naming = f'{i[0]}_Siberia_{year}_{tilename}'\n",
    "        download_image(i[1], naming, 'PeatFire', studyArea, crs, scale=scale, \n",
    "                   transform=None, logfile=logfile)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045391c1-6171-4cb0-bfb2-f87b92c5eb77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T18:17:49.630184Z",
     "start_time": "2024-11-20T18:16:46.207215Z"
    }
   },
   "outputs": [],
   "source": [
    "Extent = ee.Geometry.BBox(63, 58, 180, 74)\n",
    "Tiles = grid4d.aggregate_array('TILE').getInfo()\n",
    "for year in list(range(2023, 2000, -1))[:]:\n",
    "    print(year)\n",
    "    LST_anomaly(year, Extent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112b11a6-ebee-4e10-9160-1179c1fe436f",
   "metadata": {},
   "source": [
    "## 5) VCF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e102e086-0b97-4e88-bfa9-f5e04360dfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_VCF(year, studyArea, tile=None, logfile=False):\n",
    "    if not logfile:\n",
    "        logfile = io.StringIO()\n",
    "    if tile:    \n",
    "        studyArea = tile.geometry()\n",
    "        tilename = tile.get('TILE').getInfo()    \n",
    "    vcf = ee.ImageCollection(\"MODIS/006/MOD44B\") \\\n",
    "          .filter(ee.Filter.date(f'{year}-01-01', f'{year+1}-01-01'))\n",
    "    vcf = vcf.first().select(['Percent_Tree_Cover', 'Percent_NonTree_Vegetation']) \\\n",
    "                  .rename(['tree_cover', 'nontree_cover'])\n",
    "    proj = vcf.projection().getInfo()\n",
    "    crs = proj['crs']\n",
    "    crs = 'EPSG:4326'\n",
    "    gt = proj['transform']\n",
    "    scale = gt[0]\n",
    "    print(crs, gt)\n",
    "    naming = f'MOD44B_VCF_Siberia_{year}'\n",
    "    if tile:\n",
    "        naming = f'MOD44B_VCF_Siberia_{year}_{tilename}'\n",
    "    download_image(vcf, naming, 'PeatFire', studyArea, crs, scale=scale, \n",
    "               transform=None, logfile=logfile)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa70401-5720-4522-8183-dd1e670536e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Extent = ee.Geometry.BBox(60, 58, 180, 74)\n",
    "Tiles = grid4d.aggregate_array('TILE').getInfo()\n",
    "for year in list(range(2016, 2000, -1))[:]:\n",
    "    print(year)\n",
    "    get_VCF(year, Extent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cdfb0e-3476-4726-b87c-1f4847cbaf49",
   "metadata": {},
   "source": [
    "## 6) ALOS DEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f17b542-9844-47ab-b8b1-a9af77af1778",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_DEM(studyArea, tile=None, logfile=False):\n",
    "    if not logfile:\n",
    "        logfile = io.StringIO()\n",
    "    if tile:    \n",
    "        studyArea = tile.geometry()\n",
    "        tilename = tile.get('TILE').getInfo()    \n",
    "    dataset = ee.ImageCollection('JAXA/ALOS/AW3D30/V3_2').filterBounds(studyArea)\n",
    "    elevation = dataset.select('DSM')\n",
    "    proj = elevation.first().select(0).projection()\n",
    "    elevation_gee = elevation.mosaic().setDefaultProjection(proj).rename('elevation')\n",
    "    bandtype = elevation_gee.bandTypes().get('elevation')\n",
    "    # elevation_gee = elevation_gee.addBands(ee.Image.pixelLonLat())\n",
    "    slope_gee = ee.Terrain.slope(elevation_gee).multiply(100).cast({'slope': bandtype})\n",
    "    aspect_gee = ee.Terrain.aspect(elevation_gee).convolve(ee.Kernel.square(1, 'pixels')).cast({'aspect': bandtype})\n",
    "    topo = elevation_gee.addBands(slope_gee).addBands(aspect_gee)\n",
    "    BA_image = BA30.qualityMosaic('b1')\n",
    "    # print(BA_image.getInfo())\n",
    "    topo = topo.updateMask(BA_image.gt(0))\n",
    "    print(topo.getInfo())\n",
    "    proj = proj.getInfo()\n",
    "    crs = proj['crs']\n",
    "    gt = proj['transform']\n",
    "    print(crs, gt)\n",
    "    naming = f'ALOSDEM30_Siberia'\n",
    "    if tile:\n",
    "        naming = f'ALOSDEM30_Siberia_{tilename}'\n",
    "    download_image(topo, naming, 'PeatFire', studyArea, crs, scale=None, \n",
    "               transform=gt, logfile=logfile)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c3cc28-0e85-407b-a9a6-d4f2b39b793c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Extent = ee.Geometry.BBox(60, 58, 180, 74)\n",
    "Tiles = grid4d.aggregate_array('TILE').getInfo()\n",
    "# tile = 'TILE-66N108E'\n",
    "for tile in Tiles[:]:\n",
    "    tile = grid4d.filter(ee.Filter.eq('TILE', tile)).first()\n",
    "    get_DEM(Extent, tile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e26583",
   "metadata": {},
   "source": [
    "## 7)  AGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65f835c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T14:04:17.344294Z",
     "start_time": "2024-11-23T14:04:17.340784Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_agb(studyArea, tile=None, logfile=False):\n",
    "    if not logfile:\n",
    "        logfile = io.StringIO()\n",
    "    if tile:    \n",
    "        studyArea = tile.geometry()\n",
    "        tilename = tile.get('TILE').getInfo()  \n",
    "        \n",
    "    AGB = ee.ImageCollection(\"projects/sat-io/open-datasets/ESA/ESA_CCI_AGB\").first().select('AGB')    ##2010\n",
    "    BA_image = BA30.qualityMosaic('b1')\n",
    "    AGB = AGB.updateMask(BA_image.gt(0).focalMax(kernel=ee.Kernel.euclidean(4, units='pixels'), iterations=1))\n",
    "    proj = AGB.projection().getInfo()\n",
    "    crs = proj['crs']\n",
    "    gt = proj['transform']\n",
    "    print(crs, gt)\n",
    "    naming = f'AGB2010_Siberia'\n",
    "    if tile:\n",
    "        naming = f'{naming}_{tilename}'\n",
    "    download_image(AGB, naming, 'PeatFire', studyArea, crs, scale=None, \n",
    "               transform=gt, logfile=logfile)   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ccaaf4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T14:04:22.701735Z",
     "start_time": "2024-11-23T14:04:20.994802Z"
    }
   },
   "outputs": [],
   "source": [
    "Extent = ee.Geometry.BBox(63, 58, 180, 74)\n",
    "get_agb(Extent, tile=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1c3f54-f704-4438-8b24-5809257a0a7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T12:43:00.790111Z",
     "iopub.status.busy": "2024-11-03T12:43:00.789375Z",
     "iopub.status.idle": "2024-11-03T12:43:00.796323Z",
     "shell.execute_reply": "2024-11-03T12:43:00.795779Z",
     "shell.execute_reply.started": "2024-11-03T12:43:00.790064Z"
    }
   },
   "source": [
    "## Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c1d60f-f01f-456e-90ea-06d56c5311e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T19:01:50.442776Z",
     "start_time": "2024-11-23T19:01:50.438949Z"
    },
    "execution": {
     "iopub.execute_input": "2024-11-05T12:22:23.809955Z",
     "iopub.status.busy": "2024-11-05T12:22:23.809638Z",
     "iopub.status.idle": "2024-11-05T12:22:23.815288Z",
     "shell.execute_reply": "2024-11-05T12:22:23.814766Z",
     "shell.execute_reply.started": "2024-11-05T12:22:23.809928Z"
    }
   },
   "outputs": [],
   "source": [
    "def resample_vars(layer, tile, Tiles4d, input_path, local_path, tiled, \n",
    "                  yearly, year, logfile=False):\n",
    "    if not logfile:\n",
    "        logfile = io.StringIO()\n",
    "    Global_Functions.print_and_log(logfile, f'\\n\\t\\t{15 * \"-\"} {tile} {15 * \"-\"}')   \n",
    "\n",
    "    ref = f'{local_path}/ByTile/{tile}/Enhanced/Yearly/BAMT_BA_Siberia_Lndst_{year}_{tile}_JD_Correct_Patches.tif'\n",
    "    with rio.open(ref) as src:\n",
    "        profile = src.profile\n",
    "    lon = int(tile[8:11])\n",
    "    lat = int(tile[5:7])\n",
    "    \n",
    "    if tiled:\n",
    "        lon6d = lon if lon in np.array(Tiles4d)[:, 1] else lon-3\n",
    "        lat4d = lat if lat in np.array(Tiles4d)[:, 0] else lat+2\n",
    "        filenames = glob.glob(f\"{input_path}/{layer}/{layer}*\" + yearly*f\"_{year}\" + f\"_TILE-{lat4d:02}N{lon6d:03}E*.tif\")\n",
    "    else:\n",
    "        filenames = glob.glob(f\"{input_path}/{layer}/{layer}*\" + yearly*f\"_{year}*\" + f\".tif\")\n",
    "\n",
    "    with rio.open(filenames[0]) as src:\n",
    "        profile['dtype'] = src.profile['dtype']\n",
    "    naming = f\"{layer}_Siberia\" + yearly*f\"_{year}\" + f\"_{tile}\"\n",
    "    Global_Functions.mosaic_gdal(naming, files=filenames, pattern='', inputPath='', \n",
    "            outPath=f'{local_path}/PeatFire/ByTile/{tile}/Predictors', vrtPath='/vsimem', profile=profile)  \n",
    "    Global_Functions.print_and_log(logfile, f'\\t\\t+++++ {naming} is saved +++++\\n')\n",
    "        \n",
    "    # return {'tile': tile, 'text': logfile.getvalue()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd47e937-45b6-4f18-a61e-ab20cd9b274e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T19:03:55.618456Z",
     "start_time": "2024-11-23T19:01:56.464994Z"
    },
    "execution": {
     "iopub.execute_input": "2024-11-07T04:35:00.976760Z",
     "iopub.status.busy": "2024-11-07T04:35:00.976577Z",
     "iopub.status.idle": "2024-11-07T04:41:52.819742Z",
     "shell.execute_reply": "2024-11-07T04:41:52.819243Z",
     "shell.execute_reply.started": "2024-11-07T04:35:00.976746Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "local_path = '/media/amin/STORAGE/STORAGE/OneDrive/PhD/Landsat_BA'\n",
    "raw_path = '/media/amin/STORAGE/STORAGE/OneDrive/PhD/Landsat_BA/Siberia/PeatFire/BG_CC/data'\n",
    "res_path = '/media/amin/DISK6T/PhD/Landsat_BA/Siberia'\n",
    "sib4d = gpd.read_file(f'{local_path}/Regions/Tiles_Siberia_4dLat.shp')\n",
    "sib3d = gpd.read_file(f'{local_path}/Regions/Tiles_Siberia_3dLon.shp')\n",
    "Tiles4d = [(int(i[5:7]), int(i[8:11]))  for i in sib4d.TILE]\n",
    "Tiles = ['TILE-' + i for i in sib3d.TILE]\n",
    "\n",
    "# LogFile = open(f\"{res_path}/PeatFire/Logs/Logfile_Siberia_PeatFire_Predictors_Resampling.txt\", 'w')\n",
    "LogFile = io.StringIO()\n",
    "Global_Functions.print_and_log(LogFile, \n",
    "            f'{30 * \"-\"} Logfile of PeatFire Predictors Resampling {30 * \"-\"}\\n\\n')\n",
    "layer_args = dict(\n",
    "            MOD44B_VCF = {'tiled': False, 'yearly': True, 'years': range(2001, 2021)},\n",
    "            LST_Mean = {'tiled': False, 'yearly': True, 'years': range(2001, 2024)},\n",
    "            LST_std_anomaly = {'tiled': False, 'yearly': True, 'years': range(2001, 2024)},\n",
    "            LST_persistence = {'tiled': False, 'yearly': True, 'years': range(2001, 2024)}, \n",
    "            TerraClimate_Means = {'tiled': False, 'yearly': True, 'years': range(2001, 2024)},\n",
    "            TerraClimate_Anomalies = {'tiled': False, 'yearly': True, 'years': range(2001, 2024)},\n",
    "            ECMWF_CEMS_Means = {'tiled': False, 'yearly': True, 'years': range(2001, 2024)},\n",
    "            ECMWF_CEMS_Anomalies = {'tiled': False, 'yearly': True, 'years': range(2001, 2024)},\n",
    "            ALOSDEM30 = {'tiled': True, 'yearly': False, 'years': [2021]},\n",
    "            NBR = {'tiled': True, 'yearly': True, 'years': range(2001, 2024)},\n",
    "            AGB2010 = {'tiled': False, 'yearly': False, 'years': [2021]}\n",
    "            )\n",
    "time0 = datetime.now()\n",
    "for year in range(2023, 2000, -1):\n",
    "    Global_Functions.print_and_log(LogFile, \n",
    "           f'\\n{10 * \"#\"} Processing of year {year} {10 * \"#\"}\\n\\n')\n",
    "    time1 = datetime.now()\n",
    "    for layer, k in layer_args.items():\n",
    "        if year in k['years']:\n",
    "            kwargs = k.copy()\n",
    "            kwargs.pop('years', None)\n",
    "            Global_Functions.print_and_log(LogFile, f'\\n\\t\\t{5 * \"*\"} {layer}')   \n",
    "            listdict = Parallel(n_jobs=12, verbose=100, backend='threading') (delayed(resample_vars) (\n",
    "                    layer, tile, Tiles4d, raw_path, res_path, **kwargs) for tile in Tiles[:]) \n",
    "            listdict.sort(key=operator.itemgetter('tile'))\n",
    "            [LogFile.write(listdict[i]['text']) for i in range(len(listdict))]\n",
    "            for i, tile in enumerate(sorted(Tiles)):\n",
    "                print(i)\n",
    "                resample_vars(layer, tile, Tiles4d, raw_path, res_path, year=year, logfile=LogFile, **kwargs)\n",
    "    time2 = datetime.now()\n",
    "    delta = time2 - time1\n",
    "    hours, minutes, seconds = Global_Functions.convert_timedelta(delta)\n",
    "    Global_Functions.print_and_log(LogFile, '\\n%s Year %s is processed in %s hours, %s minutes, %s seconds %s '\n",
    "                                  %(10 *'#', year, hours, minutes, seconds, 10 * '#'))    \n",
    "timef = datetime.now()\n",
    "delta = timef - time0    \n",
    "hours, minutes, seconds = Global_Functions.convert_timedelta(delta)\n",
    "Global_Functions.print_and_log(LogFile, '\\n\\n%s FINISHED in %s hours, %s minutes, %s seconds %s'\n",
    "                          %(20 *'-', hours, minutes, seconds, 20 * '-'))    \n",
    "LogFile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
